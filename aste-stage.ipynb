{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8109634,"sourceType":"datasetVersion","datasetId":4790350},{"sourceId":8109658,"sourceType":"datasetVersion","datasetId":4790369}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb\n!pip install transformers\n!pip install tqdm\n!pip install natasha\n!python3 -m spacy download ru_core_news_md","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile span_tagging.py\n\n# span tagging\ndef form_raw_table(d, version='3D'):\n    raw_table = [ ['' for _ in range(len(d['token']))] for _ in range(len(d['token']))]\n    aspect_index = list(set([(x[0][0],x[0][-1]) for x in d['triplets']]))\n    opinion_index = list(set([(x[1][0],x[1][-1]) for x in d['triplets']]))\n    \n    # schema\n    candidate_senti_aspect_opinion_same = {(min(t[0][0],t[1][0]), max(t[0][1],t[1][1])): t[2] for t in d['triplets']}\n    \n    candidate_senti = candidate_senti_aspect_opinion_same\n    \n    for i in range(len(d['token'])):\n        for j in range(i, len(d['token'])):\n            \n            if version == '3D':\n                raw_table[i][j] = 'A-' if (i,j) in aspect_index else 'N-'\n                raw_table[i][j] += ('O-' if (i,j) in opinion_index else 'N-')\n                raw_table[i][j] += candidate_senti[(i,j)] if (i,j) in candidate_senti else 'N'\n            elif version == '2D':\n                raw_table[i][j] = 'A-' if (i,j) in aspect_index else ( 'O-' if (i,j) in opinion_index else 'N-')\n\n                raw_table[i][j] += candidate_senti[(i,j)] if (i,j) in candidate_senti else 'N'\n            elif version == '1D':\n                raw_table[i][j] = 'A' if (i,j) in aspect_index else \\\n                                ('O' if (i,j) in opinion_index else \\\n                                ( candidate_senti[(i,j)] if (i,j) in candidate_senti  else \\\n                                'N')) \n    return raw_table\n\ndef form_label_id_map(version='3D'):\n    label_list = []\n    if version == '3D':\n        for ifA in ['N','A']:\n            for ifO in ['N','O']:\n                for ifP in ['N','NEG','NEU','POS']:\n                    label_list.append(ifA + '-' + ifO + '-' + ifP)\n    elif version == '2D':\n        for ifAO in ['N','O','A']:\n                for ifP in ['N','NEG','NEU','POS']:\n                    label_list.append(ifAO + '-' + ifP)\n    elif version == '1D':\n        label_list = ['N','NEG','NEU','POS','O','A']\n\n    label2id = {x:idx for idx, x in enumerate(label_list)}\n    id2label = {idx:x for idx, x in enumerate(label_list)}\n    return label2id, id2label\n\ndef form_sentiment_id_map():\n    label_list = ['N','NEG','NEU','POS']\n    label2id = {x:idx for idx, x in enumerate(label_list)}\n    id2label = {idx:x for idx, x in enumerate(label_list)}\n    return label2id, id2label\n\ndef map_raw_table_to_id(raw_table, label2id):\n    return [ [label2id.get(x,0) for x in y] for y in raw_table]\n\ndef map_id_to_raw_table(raw_table_id, id2label):\n    return [[id2label[x] for x in y] for y in raw_table_id]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:14:19.172104Z","iopub.execute_input":"2024-04-27T15:14:19.172431Z","iopub.status.idle":"2024-04-27T15:14:19.180985Z","shell.execute_reply.started":"2024-04-27T15:14:19.172400Z","shell.execute_reply":"2024-04-27T15:14:19.179936Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Writing span_tagging.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile greedy_inference.py\n\nimport torch\n\n# Algorithm 1: Greedy Inference\ndef loop_version_from_tag_table_to_triplets(tag_table, id2senti, version='3D'):\n    \n    raw_table_id = torch.tensor(tag_table)\n    \n    # line 1 to line 4  (get aspect/opinion/sentiment snippet)\n    if version == '1D': # {N, NEG, NEU, POS, O, A}\n        if_aspect = (raw_table_id == 5) > 0\n        if_opinion = (raw_table_id == 4) > 0\n        if_triplet = raw_table_id * ((raw_table_id > 0) * (raw_table_id < 4)) \n    else: # 2D: {N,O,A} - {N, NEG, NEU, POS}  #3D: {N,A} - {N,O} - {N, NEG, NEU, POS}\n        if_aspect = (raw_table_id & torch.tensor(8)) > 0\n        if_opinion = (raw_table_id & torch.tensor(4)) > 0\n        if_triplet = (raw_table_id & torch.tensor(3))\n    \n    m = if_triplet.nonzero()\n    senti = if_triplet[m[:,0],m[:,1]].unsqueeze(dim=-1)\n    candidate_triplets = torch.cat([m,senti,m.sum(dim=-1,keepdim=True)],dim=-1).tolist()\n    candidate_triplets.sort(key = lambda x:(x[-1],x[0]))\n    \n    \n    valid_triplets = []\n    \n    valid_triplets_set = set([])\n    \n    \n    # line 5 to line 24 (look into every sentiment snippet)\n    for r_begin, c_end, p, _ in candidate_triplets:\n        \n        #####################################################################################################\n        # CASE-1: aspect-opinion        \n        aspect_candidates = guarantee_list((if_aspect[r_begin, r_begin:(c_end+1)].nonzero().squeeze()+r_begin).tolist()) # line 7\n        opinion_candidates = guarantee_list((if_opinion[r_begin:(c_end+1),c_end].nonzero().squeeze()+r_begin).tolist())  # line 8\n        \n        \n        if len(aspect_candidates) and len(opinion_candidates):  # line 9\n            select_aspect_c = -1 if (len(aspect_candidates) == 1 or aspect_candidates[-1] != c_end) else -2     # line 10\n            select_opinion_r = 0 if (len(opinion_candidates) == 1 or opinion_candidates[0] != r_begin) else 1   # line 11\n            \n            # line 12\n            a_ = [r_begin, aspect_candidates[select_aspect_c]]  \n            o_ = [opinion_candidates[select_opinion_r], c_end] \n            s_ = id2senti[p] #id2label[p]\n            \n            # line 13\n            if str((a_,o_,s_)) not in valid_triplets_set:\n                valid_triplets.append((a_,o_,s_))\n                valid_triplets_set.add(str((a_,o_,s_)))\n            \n            \n        #####################################################################################################    \n        # CASE-2: opinion-aspect\n        opinion_candidates = guarantee_list((if_opinion[r_begin, r_begin:(c_end+1)].nonzero().squeeze()+r_begin).tolist())   # line 16\n        aspect_candidates = guarantee_list((if_aspect[r_begin:(c_end+1),c_end].nonzero().squeeze()+r_begin).tolist())        # line 17\n\n        if len(aspect_candidates) and len(opinion_candidates):  # line 18\n            select_opinion_c = -1 if (len(opinion_candidates) == 1 or opinion_candidates[-1] != c_end) else -2 # line 19\n            select_aspect_r = 0 if (len(aspect_candidates) == 1 or aspect_candidates[0] != r_begin) else 1     # line 20\n            \n            # line 21\n            o_ = [r_begin, opinion_candidates[select_opinion_c]]\n            a_ = [aspect_candidates[select_aspect_r], c_end]\n            s_ = id2senti[p] #id2label[p]\n            \n            # line 22\n            if str((a_,o_,s_)) not in valid_triplets_set:\n                valid_triplets.append((a_,o_,s_))\n                valid_triplets_set.add(str((a_,o_,s_)))\n    return {\n        'aspects': if_aspect.nonzero().squeeze().tolist(), # for ATE\n        'opinions': if_opinion.nonzero().squeeze().tolist(), # for OTE\n        'triplets': sorted(valid_triplets, key=lambda x:(x[0][0],x[0][-1],x[1][0],x[1][-1])) # line 25\n    }\n\ndef guarantee_list(l):\n    if type(l) != list:\n        l = [l]\n    return l","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:14:19.182676Z","iopub.execute_input":"2024-04-27T15:14:19.182973Z","iopub.status.idle":"2024-04-27T15:14:19.198226Z","shell.execute_reply.started":"2024-04-27T15:14:19.182940Z","shell.execute_reply":"2024-04-27T15:14:19.197338Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Writing greedy_inference.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile ASTE_dataloader.py\n\nimport torch\nimport numpy as np\nfrom collections import Counter\nfrom torch.utils.data import Dataset\n\nfrom vocab import *\nfrom span_tagging import form_raw_table,map_raw_table_to_id\nfrom tqdm import tqdm\n\nfrom natasha import (\n    Segmenter,\n    \n    NewsEmbedding,\n    NewsMorphTagger,\n    NewsSyntaxParser,\n    \n    Doc\n)\n\nsegmenter = Segmenter()\nemb = NewsEmbedding()\nmorph_tagger = NewsMorphTagger(emb)\nsyntax_parser = NewsSyntaxParser(emb)\n\n\ndef make_adj_matrix(bert_tokens, tokenizer, max_len, sep_token):\n    sent = []\n    for i in bert_tokens:\n        sent.append(tokenizer.decode([i]))\n        if i == sep_token:\n            break\n    new_sent = \"\"\n    new_inds = [] # from tokens to poses in text\n    new_inds_mapping = {}\n    index = -1\n    for idx, i in enumerate(sent[1:-1]):\n        if i[:2] == '##':\n            new_sent += i[2:]\n        else:\n            new_sent += \" \"\n            new_sent += i\n            index += 1\n        new_inds.append(index)\n\n    new_inds_mapping[0] = [0]\n    for idx, i in enumerate(new_inds):\n        if new_inds_mapping.get(i + 1):\n            new_inds_mapping[i + 1].append(idx + 1)\n        else:\n            new_inds_mapping[i + 1] = [idx + 1]\n\n    new_sent = new_sent.strip()\n    text = new_sent\n\n    splitted_text = text.split(\" \")\n\n    doc = Doc(text)\n    doc.segment(segmenter)\n    doc.tag_morph(morph_tagger)\n    doc.parse_syntax(syntax_parser)\n    \n    doc_sents_lens = [0]\n    for i in doc.sents:\n        doc_sents_lens.append(doc_sents_lens[-1] + len(i.tokens))\n    \n    cnt = 0\n    i = 0\n    j = 0\n    splitted_mapping = {0:[0]} # from poses from the text to segmented words\n    while i < len(doc.tokens) and j < len(splitted_text):\n        cur_nat_text = doc.tokens[i].text\n        cur_our_text = splitted_text[j]\n        if cur_nat_text == cur_our_text:\n            splitted_mapping[i + 1] = [j + 1]\n            i += 1\n            j += 1\n        else:\n            splitted_mapping[i + 1] = [j + 1]\n            if len(cur_nat_text) < len(cur_our_text):\n                while cur_nat_text != cur_our_text:\n                    i += 1\n                    splitted_mapping[i + 1] = [j + 1]\n\n                    cur_nat_text += doc.tokens[i].text\n            elif len(cur_nat_text) > len(cur_our_text):\n                while cur_nat_text != cur_our_text:\n                    j += 1\n                    splitted_mapping[i + 1].append(j + 1)\n                    cur_our_text += splitted_text[j]\n            else:\n                raise \"???\"\n            i += 1\n            j += 1\n\n    adj_matrix = np.eye(max_len, max_len)\n\n    for i in doc.tokens:\n        sent_id, cur_id = [int(j)  for j in i.id.split('_')]\n        head_sent_id, head_id = [int(j) for j in i.head_id.split('_')]\n        cur_words_ids = []\n        for j in splitted_mapping[doc_sents_lens[sent_id - 1] + cur_id]:\n            for k in new_inds_mapping[j]:\n                cur_words_ids.append(k)\n        cur_words_head_ids = []\n        for j in splitted_mapping[doc_sents_lens[head_sent_id - 1] + head_id]:\n            for k in new_inds_mapping[j]:\n                cur_words_head_ids.append(k)\n        for i in cur_words_ids:\n            for j in cur_words_head_ids:\n                adj_matrix[i][j] = 1\n\n    return torch.FloatTensor(adj_matrix).to_sparse()\n\n\nclass ASTE_End2End_Dataset(Dataset):\n    def __init__(self, file_name, vocab = None, version = '3D', tokenizer = None, max_len = 128, lower=True, is_clean = True):\n        super().__init__()\n        \n        self.max_len = max_len\n        self.lower = lower\n        self.version = version\n        \n        if type(file_name) is str:\n            with open(file_name,'r',encoding='utf-8') as f:\n                lines = f.readlines()\n                self.raw_data = [line2dict(l, is_clean = is_clean) for l in lines]\n        else:\n            self.raw_data = file_name\n        \n        self.tokenizer = tokenizer\n        self.data = self.preprocess(self.raw_data, vocab=vocab, version=version)\n    \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n    \n    def text2bert_id(self, token):\n        re_token = []\n        word_mapback = []\n        word_split_len = []\n        for idx, word in enumerate(token):\n            temp = self.tokenizer.tokenize(word)\n            re_token.extend(temp)\n            word_mapback.extend([idx] * len(temp))\n            word_split_len.append(len(temp))\n        re_id = self.tokenizer.convert_tokens_to_ids(re_token)\n        return re_id, word_mapback, word_split_len\n    \n    def preprocess(self, data, vocab, version):\n        \n        token_vocab = vocab['token_vocab']\n        label2id = vocab['label_vocab']['label2id']\n        processed = []\n        max_len = self.max_len\n        CLS_id = self.tokenizer.convert_tokens_to_ids([self.tokenizer.cls_token])\n        SEP_id = self.tokenizer.convert_tokens_to_ids([self.tokenizer.sep_token])\n        \n        for d in tqdm(data, 'Loading data...'):\n            golden_label = map_raw_table_to_id(form_raw_table(d, version=version),label2id) if 'triplets' in d else None\n            tok = d['token']\n            if self.lower:\n                tok = [t.lower() for t in tok]\n            \n            text_raw_bert_indices, word_mapback, _ = self.text2bert_id(tok)\n            text_raw_bert_indices = text_raw_bert_indices[:max_len]\n            word_mapback = word_mapback[:max_len]\n            \n            length = word_mapback[-1] + 1\n            if length != len(tok):\n                print(tok)\n                print(len(tok))\n                print(word_mapback)\n                print(len(word_mapback))\n            assert(length == len(tok))\n            bert_length = len(word_mapback)\n            \n            bert_token = CLS_id + text_raw_bert_indices + SEP_id\n            \n            tok = tok[:length]\n            adj_matrix = make_adj_matrix(bert_token, self.tokenizer, self.max_len, SEP_id)\n            tok = [token_vocab.stoi.get(t, token_vocab.unk_index) for t in tok]\n            \n            temp = {\n                'adj_matrix': adj_matrix,\n                'token': tok,\n                'token_length': length,\n                'bert_token': bert_token,\n                'bert_length': bert_length,\n                'bert_word_mapback': word_mapback,\n                'golden_label': golden_label\n\n            }\n            processed.append(temp)\n        return processed\n    \ndef ASTE_collate_fn(batch):\n    batch_size = len(batch)\n    \n    re_batch = {}\n    \n    token = get_long_tensor([ batch[i]['token'] for i in range(batch_size)])\n    \n    adj_matrix = torch.cat([batch[i]['adj_matrix'].unsqueeze(0) for i in range(batch_size)], axis=0)\n    token_length = torch.tensor([batch[i]['token_length'] for i in range(batch_size)])\n    bert_token = get_long_tensor([batch[i]['bert_token'] for i in range(batch_size)])\n    bert_length = torch.tensor([batch[i]['bert_length'] for i in range(batch_size)])\n    bert_word_mapback = get_long_tensor([batch[i]['bert_word_mapback'] for i in range(batch_size)])\n\n    golden_label = np.zeros((batch_size, token_length.max(), token_length.max()),dtype=np.int64)\n    \n    if batch[0]['golden_label'] is not None:\n        for i in range(batch_size):\n            golden_label[i, :token_length[i], :token_length[i]] = batch[i]['golden_label']\n\n    golden_label = torch.from_numpy(golden_label)\n    \n    re_batch = {\n        'adj_matrix': adj_matrix,\n        'token' : token,\n        'token_length' : token_length,\n        'bert_token' : bert_token,\n        'bert_length' : bert_length,\n        'bert_word_mapback' : bert_word_mapback,\n        'golden_label' : golden_label\n    }\n    \n    return re_batch\n\ndef get_long_tensor(tokens_list, max_len=None):\n    \"\"\" Convert list of list of tokens to a padded LongTensor. \"\"\"\n    batch_size = len(tokens_list)\n    token_len = max(len(x) for x in tokens_list) if max_len is None else max_len\n    tokens = torch.LongTensor(batch_size, token_len).fill_(0)\n    for i, s in enumerate(tokens_list):\n        tokens[i, : min(token_len,len(s))] = torch.LongTensor(s)[:token_len]\n    return tokens\n\n\n############################################################################\n# data preprocess\ndef clean_data(l):\n    token, triplets = l.strip().split('####')\n    temp_t  = list(set([str(t) for t in eval(triplets) ]))\n    return token + '####' + str([eval(t) for t in temp_t]) + '\\n'\n\ndef line2dict(l, is_clean=False):\n    if is_clean:\n        l = clean_data(l)\n    sentence, triplets = l.strip().split('####')\n    start_end_triplets = []\n    for t in eval(triplets):\n        start_end_triplets.append(tuple([[t[0][0],t[0][-1]],[t[1][0],t[1][-1]],t[2]]))\n    start_end_triplets.sort(key=lambda x: (x[0][0],x[1][-1])) # sort ?\n    return dict(token=sentence.split(' '), triplets=start_end_triplets)\n\n\n#############################################################################\n# vocab\ndef build_vocab(dataset):\n    tokens = []\n    \n    files = ['train_triplets.txt','dev_triplets.txt','test_triplets.txt']\n    for file_name in files:\n        file_path = dataset + '/' + file_name\n        with open(file_path,'r',encoding='utf-8') as f:\n            lines = f.readlines()\n        \n        for l in lines:\n            cur_token = l.strip().split('####')[0].split()\n            tokens.extend(cur_token)\n    return tokens\n\ndef load_vocab(dataset_dir,lower=True):\n    tokens = build_vocab(dataset_dir)\n    if lower:\n        tokens = [w.lower() for w in tokens]\n    token_counter = Counter(tokens)\n    token_vocab = Vocab(token_counter, specials=[\"<pad>\", \"<unk>\"])\n    vocab = {'token_vocab':token_vocab}\n    return vocab","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:25:11.550839Z","iopub.execute_input":"2024-04-27T15:25:11.551284Z","iopub.status.idle":"2024-04-27T15:25:11.566762Z","shell.execute_reply.started":"2024-04-27T15:25:11.551246Z","shell.execute_reply":"2024-04-27T15:25:11.565817Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Overwriting ASTE_dataloader.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile vocab.py\n\n\nimport pickle\n\nclass Vocab(object):\n    def __init__(self, counter, specials=[\"<pad>\", \"<unk>\"]):\n        self.pad_index = 0\n        self.unk_index = 1\n        counter = counter.copy()\n        self.itos = list(specials)\n        for tok in specials:\n            del counter[tok]\n\n        # sort by frequency, then alphabetically\n        words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n        words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n\n        for word, _ in words_and_frequencies:\n            self.itos.append(word)\n\n        # stoi is simply a reverse dict for itos\n        self.stoi = {tok: i for i, tok in enumerate(self.itos)}\n\n    def __eq__(self, other):\n        if self.stoi != other.stoi:\n            return False\n        if self.itos != other.itos:\n            return False\n        return True\n\n    def __len__(self):\n        return len(self.itos)\n\n    def extend(self, v):\n        words = v.itos\n        for w in words:\n            if w not in self.stoi:\n                self.itos.append(w)\n                self.stoi[w] = len(self.itos) - 1\n        return self\n\n    @staticmethod\n    def load_vocab(vocab_path: str):\n        with open(vocab_path, \"rb\") as f:\n            print('Loading vocab from:', vocab_path)\n            return pickle.load(f)\n\n    def save_vocab(self, vocab_path):\n        with open(vocab_path, \"wb\") as f:\n            print('Saving vocab to:', vocab_path)\n            pickle.dump(self, f)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:14:19.200732Z","iopub.execute_input":"2024-04-27T15:14:19.200996Z","iopub.status.idle":"2024-04-27T15:14:19.211756Z","shell.execute_reply.started":"2024-04-27T15:14:19.200973Z","shell.execute_reply":"2024-04-27T15:14:19.210936Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Writing vocab.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile V_calc_metrics.py\n\n\nclass Metrics_V:\n    def __init__(self):\n        pass\n\n    def _drop_duplicates(self, samples):\n        return {sample_id: set(aspects) for sample_id, aspects in samples.items()}\n\n    def calculate(self, true, predicted):\n        true = self._drop_duplicates(true)\n        predicted = self._drop_duplicates(predicted)\n\n        assert len(true) == len(predicted)\n\n        self.tp = 0\n        self.fp = 0\n        self.fn = 0\n        for sample_id in (set(true) | set(predicted)):\n            if sample_id not in true:\n                raise ValueError(f\"Sample id {sample_id} is not found in true aspects\")\n            if sample_id not in predicted:\n                raise ValueError(f\"Sample id {sample_id} is not found in predicted aspects\")\n\n            true_aspects = true[sample_id]\n            pred_aspects = predicted[sample_id]\n\n            current_tp = sum(pred_aspect in true_aspects for pred_aspect in pred_aspects)\n            current_fp = len(pred_aspects) - current_tp\n            current_fn = sum(true_aspect not in pred_aspects for true_aspect in true_aspects)\n            \n            self.tp += current_tp\n            self.fp += current_fp\n            self.fn += current_fn\n\n        # return self.precision()\n\n    @property\n    def precision(self) -> float:\n        if self.tp + self.fp == 0:\n            return 0\n        return self.tp / (self.tp + self.fp)\n    \n    @property\n    def recall(self) -> float:\n        if self.tp + self.fn == 0:\n            return 0\n        return self.tp / (self.tp + self.fn)\n\n    @property\n    def f1(self) -> float:\n        if self.precision + self.recall == 0:\n            return 0\n        return 2 * self.precision * self.recall / (self.precision + self.recall)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:14:19.212756Z","iopub.execute_input":"2024-04-27T15:14:19.213015Z","iopub.status.idle":"2024-04-27T15:14:19.227318Z","shell.execute_reply.started":"2024-04-27T15:14:19.212992Z","shell.execute_reply":"2024-04-27T15:14:19.226407Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Writing V_calc_metrics.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile evaluate.py\n\nimport torch\nimport json\nfrom collections import Counter\nfrom greedy_inference import loop_version_from_tag_table_to_triplets\n\nfrom V_calc_metrics import Metrics_V\n\ndef evaluate_model(model, test_dataset, test_dataloader, id2senti, device='cuda', version = '3D', weight = None, saved_file=None):\n    model.eval()\n    model.bert.eval()\n    total_loss = 0.0\n    total_step = 0\n\n    saved_token = [test_dataset.raw_data[idx]['token'] for idx in range(len(test_dataset.raw_data))]\n    saved_golds = [test_dataset.raw_data[idx]['triplets'] for idx in range(len(test_dataset.raw_data))]\n    \n    saved_preds = []\n    saved_aspects = []\n    saved_opinions = []\n\n    my_metric = Metrics_V()\n\n    true_dict = {}\n    pred_dict = {}\n\n    with torch.no_grad():\n        for batch in test_dataloader:\n            inputs = {k:v.to(device) for k,v in batch.items()}\n        \n            outputs = model(inputs, weight)\n\n            loss = outputs['loss']\n            total_step += 1\n            total_loss += loss.item()\n\n            batch_raw_table_id = torch.argmax(outputs['logits'],dim=-1)\n            for idx in range(len(batch_raw_table_id)):\n                pred_triplets = loop_version_from_tag_table_to_triplets(tag_table = batch_raw_table_id[idx].tolist(), \n                                                            id2senti = id2senti, \n                                                            version=version)\n                \n                saved_preds.append(pred_triplets['triplets'])\n                saved_aspects.append(pred_triplets['aspects'])\n                saved_opinions.append(pred_triplets['opinions'])\n\n    true_dict = {}\n    pred_dict = {}\n    num = 0\n    for i_pred, i_gold in zip(saved_preds, saved_golds):\n        pred_dict[num] = set()\n        for i in i_pred:\n            pred_dict[num].add(\"|\".join([str(j) for j in i]))\n        true_dict[num] = set()\n        for i in i_gold:\n            true_dict[num].add(\"|\".join([str(j) for j in i]))\n        num += 1\n        \n    my_metric.calculate(true_dict, pred_dict)\n    print(\"My metrics: precision: {:.6f}\\trecall: {:.6f}\\tf1: {:.6f}\".format(\n        my_metric.precision, my_metric.recall, my_metric.f1))\n    \n\n    if saved_file is not None:\n        with open(saved_file,'w') as f:\n            combined = [\n                dict(token=token, pred=pred, gold=gold, pred_aspect = pred_aspect, pred_opinion=pred_opinion) \\\n                    for token,pred,gold,pred_aspect,pred_opinion in zip(saved_token,saved_preds, saved_golds, saved_aspects, saved_opinions)\n            ]\n            json.dump(combined, f)\n\n    loss = total_loss / total_step\n    evaluate_dict = evaluate_predictions(preds = saved_preds, goldens = saved_golds, preds_aspect = saved_aspects, preds_opinion = saved_opinions)\n    model.train()\n    return loss, evaluate_dict\n\n\ndef evaluate_predictions(preds = None, goldens = None, preds_aspect = None, preds_opinion = None):\n    counts = Counter()\n    \n    one_counts = Counter()\n    multi_counts = Counter()\n    aspect_counts = Counter()\n    opinion_counts = Counter()\n\n    \n    ate_counts = Counter()\n    ote_counts = Counter()\n    \n    for pred, gold, pred_aspect,pred_opinion in zip(preds,goldens,preds_aspect,preds_opinion):\n        counts = evaluate_sample(pred, gold, counts)\n    \n        pred_one,pred_new_multi, pred_a_multi, pred_o_multi = get_spereate_triplets(pred)\n        one,new_multi, a_multi, o_multi = get_spereate_triplets(gold)\n        \n        one_counts = evaluate_sample(pred_one, one, one_counts)\n        multi_counts = evaluate_sample(pred_new_multi, new_multi, multi_counts)\n        aspect_counts = evaluate_sample(pred_a_multi, a_multi, aspect_counts)\n        opinion_counts = evaluate_sample(pred_o_multi, o_multi, opinion_counts)\n        \n        gold_ate = [[m[0],m[1]] for m in list(set([tuple(x[0]) for x in gold]))]\n        gold_ote = [[m[0],m[1]] for m in list(set([tuple(x[1]) for x in gold]))]\n        \n        if len(pred_aspect) > 0 and type(pred_aspect[0]) is int:\n            pred_aspect = [pred_aspect]\n            \n        if len(pred_opinion) > 0 and  type(pred_opinion[0]) is int:\n            pred_opinion = [pred_opinion]\n        \n        ate_counts = evaluate_term(pred=pred_aspect, gold=gold_ate, counts = ate_counts)\n        ote_counts = evaluate_term(pred=pred_opinion, gold = gold_ote, counts = ote_counts)\n    \n    all_scores = output_score_dict(counts)\n    one_scores = output_score_dict(one_counts)\n    multi_scores = output_score_dict(multi_counts)\n    aspect_scores = output_score_dict(aspect_counts)\n    opinion_scores = output_score_dict(opinion_counts)\n    term_scores = output_score_dict_term(ate_counts, ote_counts)\n    \n    return all_scores, one_scores, multi_scores, aspect_scores, opinion_scores, term_scores\n\n###############################################################################################\n# ASTE (AOPE)\ndef evaluate_sample(pred, gold, counts = None):\n    if counts is None:\n        counts = Counter()\n    \n    correct_aspect = set()\n    correct_opinion = set()\n    \n    # ASPECT.\n    aspect_golden = list(set([tuple(x[0]) for x in gold]))\n    aspect_predict = list(set([tuple(x[0]) for x in pred]))\n\n    counts['aspect_golden'] += len(aspect_golden)\n    counts['aspect_predict'] += len(aspect_predict)\n    \n    \n    for prediction in aspect_predict:\n        if any([prediction == actual for actual in aspect_golden]):\n            counts['aspect_matched'] += 1\n            correct_aspect.add(prediction)\n\n    # OPINION.\n    opinion_golden = list(set([tuple(x[1]) for x in gold]))\n    opinion_predict = list(set([tuple(x[1]) for x in pred]))\n    \n    counts['opinion_golden'] += len(opinion_golden)\n    counts['opinion_predict'] += len(opinion_predict)\n    \n    \n    for prediction in opinion_predict:\n        if any([prediction == actual for actual in opinion_golden]):\n            counts['opinion_matched'] += 1\n            correct_opinion.add(prediction)\n\n    triplets_golden = [(tuple(x[0]),tuple(x[1]), x[2]) for x in gold]\n    triplets_predict = [(tuple(x[0]),tuple(x[1]), x[2]) for x in pred]\n    \n    counts['triplet_golden'] += len(triplets_golden)\n    counts['triplet_predict'] += len(triplets_predict)\n    for prediction in triplets_predict:\n        if any([prediction[:2] == actual[:2] for actual in triplets_golden]):\n            counts['pair_matched'] += 1\n\n        if any([prediction == actual for actual in triplets_golden]):\n            counts['triplet_matched'] += 1\n                \n\n    # Return the updated counts.\n    return counts\n\ndef output_score_dict(counts):\n    scores_aspect = compute_f1(counts['aspect_predict'], counts['aspect_golden'], counts['aspect_matched'])\n    scores_opinion = compute_f1(counts['opinion_predict'], counts['opinion_golden'], counts['opinion_matched'])\n    \n    scores_pair = compute_f1(counts['triplet_predict'], counts['triplet_golden'], counts['pair_matched'])\n    scores_triplet = compute_f1(counts['triplet_predict'], counts['triplet_golden'], counts['triplet_matched'])\n    \n    return dict(aspect=scores_aspect, opinion=scores_opinion, pair=scores_pair, triplet=scores_triplet)\n\n###############################################################################################\n# ATE & OTE\ndef evaluate_term(pred, gold, counts=None):\n    if counts is None:\n        counts = Counter()\n\n    counts['golden'] += len(gold)\n    counts['predict'] += len(pred)\n    \n    for prediction in pred:\n        if any([prediction == actual for actual in gold]):\n            counts['matched'] += 1\n    return counts\n\n\ndef output_score_dict_term(aspect_counts, opinion_counts):\n    score_ate = compute_f1(aspect_counts['predict'], aspect_counts['golden'], aspect_counts['matched'])\n    score_ote = compute_f1(opinion_counts['predict'], opinion_counts['golden'], opinion_counts['matched'])\n    return dict(ate=score_ate, ote=score_ote)\n\n###############################################################################################\n# for additional experiments\ndef get_spereate_triplets(triplet):\n    one_triplet = []\n    new_triplet = []\n    a_triplet = []\n    o_triplet = []\n    for t in triplet:\n        if t[0][-1] != t[0][0] or t[1][-1] != t[1][0]:\n            new_triplet.append(t)\n        else:\n            one_triplet.append(t)\n        if t[0][-1] != t[0][0]:\n            a_triplet.append(t)\n        if t[1][-1] != t[1][0]:\n            o_triplet.append(t)\n    return one_triplet, new_triplet, a_triplet, o_triplet\n\ndef compute_f1(predict, golden, matched):\n    # F1 score.\n    precision = matched / predict if predict > 0 else 0\n    recall = matched / golden if golden > 0 else 0\n    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall > 0) else 0\n    return dict(precision=precision, recall=recall, f1=f1)\n\n\n##################################################################################################\n# print\ndef print_dict(d, select_k = None):\n    if select_k is None:\n        select_k = list(d.keys())\n    \n    print_str = '\\t  \\tP\\t\\tR\\t\\tF\\n'\n    for k in select_k: \n        append_plus = '*' if k in ['aspect','opinion','triplet'] else ''\n        print_str += '{:^8}\\t{:.6f}\\t{:.6f}\\t{:.6f}\\n'.format(append_plus + k.upper(),\n                                                                 d[k]['precision'], \n                                                                 d[k]['recall'], \n                                                                 d[k]['f1'])\n    print(print_str)\n    \n    \ndef print_evaluate_dict(evaluate_dict):\n    type_s = ['all','one','multi','multi_aspect','multi_opinion', 'term']\n    \n    for idx,m in enumerate(evaluate_dict):\n        print('\\n[ ' + type_s[idx], ']')\n        if type_s[idx] in ['one','multi','multi_aspect','multi_opinion']:\n            select_k = ['triplet']\n        elif type_s[idx] in ['all']:\n            select_k = ['pair','triplet']\n        else:\n            select_k = None\n        \n        print_dict(m, select_k = select_k)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:14:19.228761Z","iopub.execute_input":"2024-04-27T15:14:19.229209Z","iopub.status.idle":"2024-04-27T15:14:19.243519Z","shell.execute_reply.started":"2024-04-27T15:14:19.229175Z","shell.execute_reply":"2024-04-27T15:14:19.242681Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Writing evaluate.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile gcn.py\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nimport spacy\nimport numpy as np\n\nnlp = spacy.load(\"ru_core_news_md\")\n\nclass GCN(nn.Module):\n\n    def __init__(self, emb_dim=768, num_layers=1, gcn_dropout=0.7):             #此处dropout可以增大\n        super(GCN, self).__init__()\n        self.layers = num_layers\n        self.emb_dim = emb_dim\n        self.out_dim = emb_dim\n        input_dim = self.emb_dim\n        # gcn layer\n        self.W = nn.ModuleList([nn.Linear(input_dim, input_dim) for i in range(self.layers)])\n        self.gcn_drop = nn.Dropout(gcn_dropout)\n#         self.relu = nn.ReLU()\n        self.gelu = nn.GELU()\n\n\n    def forward(self, adj, inputs, device):\n        # gcn layer\n\n        # adj (batch_size, len, len)\n        # inputs (batch_size, len, emb_dim)\n\n        adj = adj.to_dense()\n        if inputs.shape[1] < adj.shape[1]:\n            adj = adj[:, :inputs.shape[1], :inputs.shape[1]]\n        denom = adj.sum(2).unsqueeze(2) + 1                 # batch_size, len, 1\n#         mask = (adj.sum(2) + adj.sum(1)).eq(0).unsqueeze(2) # batch_size, len, 1\n\n        for layer in range(self.layers):\n            Ax = torch.bmm(adj, inputs)        # batch_size, len, emb_dim\n            AxW = self.W[layer](Ax)            # batch_size, len, emb_dim\n            AxW = AxW + self.W[layer](inputs)  # self loop\n            AxW = AxW.to(device) / denom\n            gAxW = self.gelu(AxW)              # batch_size, len, emb_dim\n            if layer < self.layers - 1:\n                inputs = self.gcn_drop(gAxW)\n            else:\n                inputs = gAxW\n        return inputs, None # mask\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:14:19.244625Z","iopub.execute_input":"2024-04-27T15:14:19.244908Z","iopub.status.idle":"2024-04-27T15:14:19.258782Z","shell.execute_reply.started":"2024-04-27T15:14:19.244886Z","shell.execute_reply":"2024-04-27T15:14:19.257897Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Writing gcn.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile model.py\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import BertModel\nfrom transformers.models.bert.modeling_bert import BertEmbeddings\nfrom gcn import GCN\n\n\nclass base_model(nn.Module):\n    def __init__(self, pretrained_model_path, hidden_dim, dropout, args, class_n=16, \n                 span_average = False, gcn_num_layers=1, gcn_dropout=0.7):\n        super().__init__()\n        \n        self.device = args.device\n        \n        # Encoder\n        self.bert = BertModel.from_pretrained(pretrained_model_path)\n        bert_config = self.bert.config\n        if args.add_pos_enc:\n            print(\"Change pos_embeddings to 1536 len...\")\n\n            # word_emb\n            word_emb = self.bert.embeddings.word_embeddings.weight.data\n\n            # token_type_emb\n            token_type_emb = self.bert.embeddings.token_type_embeddings.weight.data\n\n            # pos_enc\n            pos_enc = self.bert.embeddings.position_embeddings.weight.data\n            new_pos_enc = torch.concat((pos_enc, pos_enc * 2, pos_enc * 4), axis=0)\n            # new_pos_enc = torch.repeat_interleave(pos_enc, 3, dim=0)\n\n            # new config and embeddings structure\n            bert_config.update({'max_position_embeddings': 1536})\n            self.bert.embeddings = BertEmbeddings(bert_config)\n\n            # return pretrained weights\n            self.bert.embeddings.word_embeddings.weight.data = word_emb\n            self.bert.embeddings.token_type_embeddings.weight.data = token_type_emb\n            self.bert.embeddings.position_embeddings.weight.data = new_pos_enc\n\n            print(\"Changed successful!\")\n\n        self.dense = nn.Linear(self.bert.pooler.dense.out_features, hidden_dim)\n        self.span_average = span_average\n\n        # Classifier\n        self.classifier = nn.Linear(hidden_dim * 3 , class_n)\n        \n        # dropout\n        self.layer_drop = nn.Dropout(dropout)\n        \n        # GCN\n        self.gcn = GCN(num_layers=gcn_num_layers, gcn_dropout=gcn_dropout)\n        \n        \n    def forward(self, inputs, weight=None):\n        \n        #############################################################################################\n        # word representation\n        bert_token = inputs['bert_token']\n        attention_mask = (bert_token > 0).int()\n        bert_word_mapback = inputs['bert_word_mapback']\n        token_length = inputs['token_length']\n        bert_length = inputs['bert_length']\n        \n        adj_martixes = inputs['adj_matrix']\n                \n        bert_output = self.bert(bert_token, attention_mask = attention_mask)\n        h_gcn, _ = self.gcn(adj_martixes.to(self.device), bert_output.last_hidden_state, self.device)\n        bert_out = bert_output.last_hidden_state + h_gcn # \\hat{h}\n        \n        bert_seq_indi = sequence_mask(bert_length).unsqueeze(dim=-1)\n        bert_out = bert_out[:, 1:max(bert_length) + 1, :] * bert_seq_indi.float()\n        word_mapback_one_hot = (F.one_hot(bert_word_mapback).float() * bert_seq_indi.float()).transpose(1, 2)\n        \n        bert_out = torch.bmm(word_mapback_one_hot.float(), self.dense(bert_out))\n        wnt = word_mapback_one_hot.sum(dim=-1)\n        wnt.masked_fill_(wnt == 0, 1)\n        bert_out = bert_out / wnt.unsqueeze(dim=-1)  # h_i\n        #############################################################################################\n        # span representation\n        \n        max_seq = bert_out.shape[1]\n        \n        token_length_mask = sequence_mask(token_length)\n        candidate_tag_mask = torch.triu(\n            torch.ones(max_seq,max_seq,dtype=torch.int64,device=bert_out.device),\n            diagonal=0).unsqueeze(dim=0) * (token_length_mask.unsqueeze(dim=1) * token_length_mask.unsqueeze(dim=-1))\n        \n        boundary_table_features = torch.cat(\n            [bert_out.unsqueeze(dim=2).repeat(1,1,max_seq,1), bert_out.unsqueeze(dim=1).repeat(1,max_seq,1,1)],\n            dim=-1) * candidate_tag_mask.unsqueeze(dim=-1)  # h_i ; h_j \n        span_table_features = form_raw_span_features(\n            bert_out, candidate_tag_mask, is_average = self.span_average) # sum(h_i,h_{i+1},...,h_{j})\n        \n        # h_i ; h_j ; sum(h_i,h_{i+1},...,h_{j})\n        table_features = torch.cat([boundary_table_features, span_table_features],dim=-1)\n       \n        #############################################################################################\n        # classifier\n        logits = self.classifier(self.layer_drop(table_features)) * candidate_tag_mask.unsqueeze(dim=-1)\n        \n        outputs = {\n            'logits':logits\n        }\n        \n        if 'golden_label' in inputs and inputs['golden_label'] is not None:\n            loss = calcualte_loss(logits, inputs['golden_label'],candidate_tag_mask, weight = weight)\n            outputs['loss'] = loss\n        \n        return outputs\n\n\ndef sequence_mask(lengths, max_len=None):\n\n    batch_size = lengths.numel()\n    max_len = max_len or lengths.max()\n    return torch.arange(0, max_len, device=lengths.device).type_as(lengths).unsqueeze(0).expand(\n        batch_size, max_len\n    ) < (lengths.unsqueeze(1))\n\ndef form_raw_span_features(v, candidate_tag_mask, is_average = True):\n    new_v = v.unsqueeze(dim=1) * candidate_tag_mask.unsqueeze(dim=-1)\n    span_features = torch.matmul(new_v.transpose(1,-1).transpose(2,-1), candidate_tag_mask.unsqueeze(dim=1).float()).transpose(2,1).transpose(2,-1)\n    \n    if is_average:\n        _, max_seq, _ = v.shape\n        sub_v = torch.tensor(range(1,max_seq+1), device = v.device).unsqueeze(dim=-1)  - torch.tensor(range(max_seq),device = v.device)\n        sub_v  = torch.where(sub_v > 0, sub_v, 1).T\n        \n        span_features = span_features / sub_v.unsqueeze(dim=0).unsqueeze(dim=-1)\n        \n    return span_features\n\ndef calcualte_loss(logits, golden_label, candidate_tag_mask, weight=None):\n    loss_func = nn.CrossEntropyLoss(weight = weight, reduction='none')\n    return (loss_func(logits.view(-1,logits.shape[-1]), \n                      golden_label.view(-1)\n                      ).view(golden_label.size()) * candidate_tag_mask).sum()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:14:19.260070Z","iopub.execute_input":"2024-04-27T15:14:19.260407Z","iopub.status.idle":"2024-04-27T15:14:19.273925Z","shell.execute_reply.started":"2024-04-27T15:14:19.260377Z","shell.execute_reply":"2024-04-27T15:14:19.273146Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Writing model.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile run.py\n\nimport os\nimport time\nimport torch\nimport random\nimport argparse\nimport numpy as np\nfrom tqdm import tqdm\nimport wandb\n\nfrom transformers import BertTokenizer\nfrom torch.utils.data import DataLoader\n\nfrom ASTE_dataloader import ASTE_End2End_Dataset, ASTE_collate_fn,load_vocab\nfrom span_tagging import form_label_id_map, form_sentiment_id_map\nfrom evaluate import evaluate_model,print_evaluate_dict\nfrom gcn import GCN\n\n\nwandb.login(key='')\n\n\ndef totally_parameters(model):\n    n_params = sum([p.nelement() for p in model.parameters()])\n    return n_params\n\ndef ensure_dir(d, verbose=True):\n    if not os.path.exists(d):\n        if verbose:\n            print(\"Directory {} do not exist; creating...\".format(d))\n        os.makedirs(d)\n\ndef form_weight_n(n):\n    if n  > 6:\n        weight = torch.ones(n)\n        index_range = torch.tensor(range(n))\n        weight = weight + ((index_range & 3) > 0)\n    else:\n        weight = torch.tensor([1.0,2.0,2.0,2.0,3.0,3.0])\n    \n    return weight\n\ndef train_and_evaluate(model_func, args, save_specific=False):\n    print('=========================================================================================================')\n    \n    set_random_seed(args.seed)\n    \n    tokenizer = BertTokenizer.from_pretrained(args.pretrained_model, do_lower_case=True)\n    dataset_dir = args.dataset_dir + '/' + args.dataset\n    saved_dir = args.saved_dir + '/' + args.dataset\n    ensure_dir(saved_dir)\n     \n    vocab = load_vocab(dataset_dir = dataset_dir)\n\n    label2id, id2label = form_label_id_map(args.version)\n    senti2id, id2senti = form_sentiment_id_map()\n    \n    vocab['label_vocab'] = dict(label2id=label2id,id2label=id2label)\n    vocab['senti_vocab'] = dict(senti2id=senti2id,id2senti=id2senti)\n\n    class_n = len(label2id)\n    args.class_n = class_n\n    weight = None\n    if args.with_weight is True:\n        weight = form_weight_n(class_n).to(args.device)\n    print('> label2id:', label2id)\n    print('> weight:', args.with_weight, weight)\n    print(args)\n\n    print('> Load model...')\n    base_model = model_func(pretrained_model_path = args.pretrained_model,\n                            hidden_dim = args.hidden_dim,\n                            dropout = args.dropout_rate,\n                            args = args,\n                            class_n = class_n,\n                            span_average = args.span_average,\n                            gcn_num_layers=3, \n                            gcn_dropout=0.5\n                            ).to(args.device)\n    \n    print('> # parameters', totally_parameters(base_model))\n    \n    print('> Load dataset...')\n    train_dataset = ASTE_End2End_Dataset(file_name = os.path.join(dataset_dir, 'train_triplets.txt'),\n                                         version = args.version,\n                                        vocab = vocab,\n                                        tokenizer = tokenizer,\n                                        max_len = args.max_len)\n    valid_dataset = ASTE_End2End_Dataset(file_name = os.path.join(dataset_dir, 'dev_triplets.txt'),\n                                         version = args.version,\n                                        vocab = vocab,\n                                        tokenizer = tokenizer,\n                                        max_len = args.max_len)\n    test_dataset = ASTE_End2End_Dataset(file_name = os.path.join(dataset_dir, 'test_triplets.txt'),\n                                        version = args.version,\n                                        vocab = vocab,\n                                        tokenizer = tokenizer,\n                                        max_len = args.max_len)\n    \n    train_dataloader = DataLoader(train_dataset, batch_size = args.batch_size, collate_fn = ASTE_collate_fn, shuffle = True)\n    valid_dataloader = DataLoader(valid_dataset, batch_size = args.batch_size, collate_fn = ASTE_collate_fn, shuffle = False)\n    test_dataloader = DataLoader(test_dataset, batch_size = args.batch_size, collate_fn = ASTE_collate_fn, shuffle = False)\n\n\n    optimizer = get_bert_optimizer(base_model, args)\n\n    triplet_max_f1 = 0.0\n\n    best_model_save_path = saved_dir +  '/' + args.dataset + '_' +  args.version + '_' + str(args.with_weight) +'_best.pkl'\n    \n    wandb.init(\n        project='aste-STAGE',\n        config=args\n    )\n    \n    scaler = torch.cuda.amp.GradScaler()\n    \n    print('> Training...')\n    for epoch in range(1, args.num_epoch+1):\n        train_loss = 0.\n        total_step = 0\n        \n        epoch_begin = time.time()\n        for batch in tqdm(train_dataloader, 'Epoch:{}'.format(epoch)):\n            base_model.train()\n            base_model.bert.train()\n            optimizer.zero_grad()\n            \n            inputs = {k:v.to(args.device) for k,v in batch.items()}\n            outputs = base_model(inputs, weight)\n            \n            loss = outputs['loss']\n            \n            total_step += 1\n            train_loss += loss.item()\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n#             loss.backward()\n#             optimizer.step()\n        \n        valid_loss, valid_results = evaluate_model(base_model, valid_dataset, valid_dataloader, \n                                                   id2senti = id2senti, \n                                                   device = args.device, \n                                                   version = args.version, \n                                                   weight = weight)\n        \n        wandb.log({\n            'train_loss': train_loss / total_step,\n            'val_loss': valid_loss,\n            'val_precision': valid_results[0]['triplet']['precision'],\n            'val_recall':valid_results[0]['triplet']['recall'],\n            'val_f1': valid_results[0]['triplet']['f1'],\n        })\n\n        print('\\ttrain_loss:{:.4f}\\tvalid_loss:{:.4f} [{:.4f}s]'.format(train_loss / total_step, \n                                                                        valid_loss,\n                                                                        time.time()-epoch_begin))\n                \n        print('\\ttriplet_precision:{:.4f} \\ttriplet_recall:{:.4f} \\ttriplet_f1:{:.4f}'.format( \n                                                    valid_results[0]['triplet']['precision'], \n                                                    valid_results[0]['triplet']['recall'], \n                                                    valid_results[0]['triplet']['f1'],\n                                                    ))\n        # save model based on the best f1 scores\n        # if valid_results[0]['triplet']['f1'] > triplet_max_f1:\n        #     triplet_max_f1 = valid_results[0]['triplet']['f1']\n            \n        #     evaluate_model(base_model, test_dataset, test_dataloader, \n        #                     id2senti = id2senti, \n        #                     device = args.device, \n        #                     version = args.version, \n        #                     weight = weight)\n        #     torch.save(base_model, best_model_save_path)\n        print(\"Test results...\")\n        _, test_results = evaluate_model(base_model, test_dataset, test_dataloader, \n                                             id2senti = id2senti, \n                                             device = args.device, \n                                             version = args.version, \n                                             weight = weight,\n                                             saved_file= \"new_gcn3_2304_run_sent_\" + str(epoch) + \".json\")\n            \n    \n    # saved_best_model = torch.load(best_model_save_path)\n    # if save_specific:\n    #     torch.save(saved_best_model, best_model_save_path.replace('_best','_' + str(args.seed) +'_best'))\n    \n    saved_file = (saved_dir + '/' + args.saved_file) if args.saved_file is not None else None\n    \n    print('> Testing...')\n    # model performance on the test set\n    _, test_results = evaluate_model(base_model, test_dataset, test_dataloader, \n                                             id2senti = id2senti, \n                                             device = args.device, \n                                             version = args.version, \n                                             weight = weight,\n                                             saved_file= saved_file)\n    \n\n    print('------------------------------')\n    \n    print('Dataset:{}, test_f1:{:.2f} | version:{} lr:{} bert_lr:{} seed:{} dropout:{}'.format(args.dataset,test_results[0]['triplet']['f1'],\n                                                                                                 args.version, args.lr, args.bert_lr, \n                                                                                                 args.seed, args.dropout_rate))\n    print_evaluate_dict(test_results)\n\n    wandb.finish()\n\n    return test_results\n\n\n\n\ndef get_bert_optimizer(model, args):\n\n    no_decay = ['bias', 'LayerNorm.weight']\n    diff_part = ['bert.embeddings', 'bert.encoder']\n    \n    \n\n    optimizer_grouped_parameters = [\n        {\n            \"params\": [p for n, p in model.named_parameters() if\n                    not any(nd in n for nd in no_decay) and any(nd in n for nd in diff_part)],\n            \"weight_decay\": args.l2,\n            \"lr\": args.bert_lr\n        },\n        {\n            \"params\": [p for n, p in model.named_parameters() if\n                    any(nd in n for nd in no_decay) and any(nd in n for nd in diff_part)],\n            \"weight_decay\": 0.0,\n            \"lr\": args.bert_lr\n        },\n        {\n            \"params\": [p for n, p in model.named_parameters() if\n                    not any(nd in n for nd in no_decay) and not any(nd in n for nd in diff_part)],\n            \"weight_decay\": args.l2,\n            \"lr\": args.lr\n        },\n        {\n            \"params\": [p for n, p in model.named_parameters() if\n                    any(nd in n for nd in no_decay) and not any(nd in n for nd in diff_part)],\n            \"weight_decay\": 0.0,\n            \"lr\": args.lr\n        },\n    ]\n    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, eps=args.adam_epsilon)\n\n    return optimizer\n\ndef set_random_seed(seed):\n\n    os.environ['PYTHONHASHSEED'] =str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.benchmark = False\n        torch.backends.cudnn.deterministic =True\n\ndef get_parameters():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--device', type=str, default='cuda')\n    parser.add_argument('--dataset_dir', type=str,default='./data/ASTE-Data-V2-EMNLP2020')\n    parser.add_argument('--saved_dir', type=str, default='saved_models')\n    parser.add_argument('--saved_file', type=str, default=None)\n    parser.add_argument('--pretrained_model', type=str, default='bert-base-uncased')\n    parser.add_argument('--dataset', type=str, default='14lap')\n    parser.add_argument('--add_pos_enc', default=False)\n    \n    parser.add_argument('--version', type=str, default='3D', choices=['3D','2D','1D'])\n    \n    parser.add_argument('--seed', type=int, default=64)\n    \n    parser.add_argument('--hidden_dim', type=int, default=200)\n    parser.add_argument('--num_epoch', type=int, default=100)\n    parser.add_argument('--batch_size', type=int, default=16)\n    parser.add_argument('--max_len', type=int, default=256)\n    \n    parser.add_argument('--lr', type=float, default=1e-3)\n    parser.add_argument('--bert_lr', type=float, default=2e-5)\n    parser.add_argument('--l2', type=float, default=0.0)\n    parser.add_argument('--dropout_rate', type=float, default=0.5)\n    parser.add_argument('--adam_epsilon', default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n    \n    # loss\n    parser.add_argument('--with_weight', default=True, action='store_true')\n    parser.add_argument('--span_average', default=False, action='store_true')\n    \n    args = parser.parse_args()\n    \n    return args\n\n\ndef run():\n    from model import base_model\n    args = get_parameters()\n#     args.with_weight = True # default true here\n        \n    train_and_evaluate(base_model, args)\n    \n\nif __name__ == '__main__':\n    run()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:14:19.275088Z","iopub.execute_input":"2024-04-27T15:14:19.275813Z","iopub.status.idle":"2024-04-27T15:14:19.294114Z","shell.execute_reply.started":"2024-04-27T15:14:19.275780Z","shell.execute_reply":"2024-04-27T15:14:19.293236Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Writing run.py\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python run.py --device 'cuda' \\\n    --dataset_dir '' --dataset '/kaggle/input/aste-dataset-full' \\\n    --pretrained_model 'ai-forever/ruBert-base' \\\n    --version '1D' \\\n    --max_len 1448 \\\n    --hidden_dim 32 \\\n    --num_epoch 20 \\\n    --batch_size 2 \\\n    --seed 42 \\\n    --add_pos_enc True \\\n    --saved_file 'new_gcn_2704_run_full_try2.json'","metadata":{"execution":{"iopub.status.busy":"2024-04-27T16:25:43.260163Z","iopub.execute_input":"2024-04-27T16:25:43.260827Z","iopub.status.idle":"2024-04-27T17:08:54.996988Z","shell.execute_reply.started":"2024-04-27T16:25:43.260789Z","shell.execute_reply":"2024-04-27T17:08:54.995882Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlmartinson\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n=========================================================================================================\n> label2id: {'N': 0, 'NEG': 1, 'NEU': 2, 'POS': 3, 'O': 4, 'A': 5}\n> weight: True tensor([1., 2., 2., 2., 3., 3.], device='cuda:0')\nNamespace(device='cuda', dataset_dir='', saved_dir='saved_models', saved_file='new_gcn_2704_run_full_try2.json', pretrained_model='ai-forever/ruBert-base', dataset='/kaggle/input/aste-dataset-full', add_pos_enc='True', version='1D', seed=42, hidden_dim=32, num_epoch=20, batch_size=2, max_len=1448, lr=0.001, bert_lr=2e-05, l2=0.0, dropout_rate=0.5, adam_epsilon=1e-08, with_weight=True, span_average=False, class_n=6)\n> Load model...\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nChange pos_embeddings to 1536 len...\nChanged successful!\n> # parameters 180890726\n> Load dataset...\nLoading data...:   0%|                                 | 0/2285 [00:00<?, ?it/s]2024-04-27 16:25:59.062962: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-27 16:25:59.063028: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-27 16:25:59.064479: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading data...: 100%|██████████████████████| 2285/2285 [05:00<00:00,  7.59it/s]\nLoading data...: 100%|████████████████████████| 490/490 [01:11<00:00,  6.88it/s]\nLoading data...: 100%|████████████████████████| 490/490 [01:07<00:00,  7.27it/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.5\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240427_163318-475flhlf\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcelestial-mountain-103\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lmartinson/aste-STAGE\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/lmartinson/aste-STAGE/runs/475flhlf/workspace\u001b[0m\n> Training...\nEpoch:1: 100%|██████████████████████████████| 1143/1143 [02:09<00:00,  8.82it/s]\nMy metrics: precision: 0.553846\trecall: 0.078261\tf1: 0.137143\n\ttrain_loss:288.2737\tvalid_loss:144.9855 [154.9397s]\n\ttriplet_precision:0.5538 \ttriplet_recall:0.0783 \ttriplet_f1:0.1371\nTest results...\nMy metrics: precision: 0.572115\trecall: 0.089205\tf1: 0.154345\nEpoch:2: 100%|██████████████████████████████| 1143/1143 [02:09<00:00,  8.83it/s]\nMy metrics: precision: 0.589372\trecall: 0.176812\tf1: 0.272018\n\ttrain_loss:125.1975\tvalid_loss:101.5682 [154.8317s]\n\ttriplet_precision:0.5894 \ttriplet_recall:0.1768 \ttriplet_f1:0.2720\nTest results...\nMy metrics: precision: 0.643052\trecall: 0.176912\tf1: 0.277484\nEpoch:3: 100%|██████████████████████████████| 1143/1143 [02:09<00:00,  8.82it/s]\nMy metrics: precision: 0.414656\trecall: 0.336232\tf1: 0.371349\n\ttrain_loss:182.3654\tvalid_loss:138.2352 [155.0015s]\n\ttriplet_precision:0.4147 \ttriplet_recall:0.3362 \ttriplet_f1:0.3713\nTest results...\nMy metrics: precision: 0.421100\trecall: 0.350075\tf1: 0.382317\nEpoch:4: 100%|██████████████████████████████| 1143/1143 [02:10<00:00,  8.77it/s]\nMy metrics: precision: 0.602972\trecall: 0.411594\tf1: 0.489233\n\ttrain_loss:108.1864\tvalid_loss:90.6671 [155.6160s]\n\ttriplet_precision:0.6030 \ttriplet_recall:0.4116 \ttriplet_f1:0.4892\nTest results...\nMy metrics: precision: 0.640756\trecall: 0.457271\tf1: 0.533683\nEpoch:5: 100%|██████████████████████████████| 1143/1143 [02:10<00:00,  8.76it/s]\nMy metrics: precision: 0.667897\trecall: 0.393478\tf1: 0.495212\n\ttrain_loss:83.4957\tvalid_loss:83.6230 [155.7717s]\n\ttriplet_precision:0.6679 \ttriplet_recall:0.3935 \ttriplet_f1:0.4952\nTest results...\nMy metrics: precision: 0.697674\trecall: 0.427286\tf1: 0.529986\nEpoch:6: 100%|██████████████████████████████| 1143/1143 [02:10<00:00,  8.79it/s]\nMy metrics: precision: 0.499311\trecall: 0.525362\tf1: 0.512006\n\ttrain_loss:98.4621\tvalid_loss:86.6028 [155.5768s]\n\ttriplet_precision:0.4993 \ttriplet_recall:0.5254 \ttriplet_f1:0.5120\nTest results...\nMy metrics: precision: 0.495346\trecall: 0.558471\tf1: 0.525018\nEpoch:7: 100%|██████████████████████████████| 1143/1143 [02:09<00:00,  8.86it/s]\nMy metrics: precision: 0.500000\trecall: 0.552899\tf1: 0.525120\n\ttrain_loss:69.3593\tvalid_loss:84.5254 [154.5156s]\n\ttriplet_precision:0.5000 \ttriplet_recall:0.5529 \ttriplet_f1:0.5251\nTest results...\nMy metrics: precision: 0.506181\trecall: 0.583208\tf1: 0.541971\nEpoch:8: 100%|██████████████████████████████| 1143/1143 [02:09<00:00,  8.80it/s]\nMy metrics: precision: 0.594340\trecall: 0.502174\tf1: 0.544383\n\ttrain_loss:88.0331\tvalid_loss:79.9444 [155.3389s]\n\ttriplet_precision:0.5943 \ttriplet_recall:0.5022 \ttriplet_f1:0.5444\nTest results...\nMy metrics: precision: 0.602205\trecall: 0.532234\tf1: 0.565062\nEpoch:9: 100%|██████████████████████████████| 1143/1143 [02:09<00:00,  8.83it/s]\nMy metrics: precision: 0.552313\trecall: 0.562319\tf1: 0.557271\n\ttrain_loss:57.4660\tvalid_loss:87.7976 [154.8178s]\n\ttriplet_precision:0.5523 \ttriplet_recall:0.5623 \ttriplet_f1:0.5573\nTest results...\nMy metrics: precision: 0.545067\trecall: 0.575712\tf1: 0.559971\nEpoch:10: 100%|█████████████████████████████| 1143/1143 [02:08<00:00,  8.89it/s]\nMy metrics: precision: 0.391802\trecall: 0.595652\tf1: 0.472685\n\ttrain_loss:62.5328\tvalid_loss:95.6451 [154.0336s]\n\ttriplet_precision:0.3918 \ttriplet_recall:0.5957 \ttriplet_f1:0.4727\nTest results...\nMy metrics: precision: 0.382693\trecall: 0.619940\tf1: 0.473247\nEpoch:11: 100%|█████████████████████████████| 1143/1143 [02:08<00:00,  8.88it/s]\nMy metrics: precision: 0.000000\trecall: 0.000000\tf1: 0.000000\n\ttrain_loss:20157.4598\tvalid_loss:371.3965 [153.9352s]\n\ttriplet_precision:0.0000 \ttriplet_recall:0.0000 \ttriplet_f1:0.0000\nTest results...\nMy metrics: precision: 0.000000\trecall: 0.000000\tf1: 0.000000\nEpoch:12: 100%|█████████████████████████████| 1143/1143 [02:09<00:00,  8.82it/s]\n^C\nTraceback (most recent call last):\n  File \"/kaggle/working/run.py\", line 308, in <module>\n    run()\n  File \"/kaggle/working/run.py\", line 304, in run\n    train_and_evaluate(base_model, args)\n  File \"/kaggle/working/run.py\", line 144, in train_and_evaluate\n    valid_loss, valid_results = evaluate_model(base_model, valid_dataset, valid_dataloader,\n  File \"/kaggle/working/evaluate.py\", line 39, in evaluate_model\n    pred_triplets = loop_version_from_tag_table_to_triplets(tag_table = batch_raw_table_id[idx].tolist(),\n  File \"/kaggle/working/greedy_inference.py\", line 7, in loop_version_from_tag_table_to_triplets\n    raw_table_id = torch.tensor(tag_table)\nKeyboardInterrupt\nTraceback (most recent call last):\n  File \"/kaggle/working/run.py\", line 308, in <module>\n    run()\n  File \"/kaggle/working/run.py\", line 304, in run\n    train_and_evaluate(base_model, args)\n  File \"/kaggle/working/run.py\", line 144, in train_and_evaluate\n    valid_loss, valid_results = evaluate_model(base_model, valid_dataset, valid_dataloader,\n  File \"/kaggle/working/evaluate.py\", line 39, in evaluate_model\n    pred_triplets = loop_version_from_tag_table_to_triplets(tag_table = batch_raw_table_id[idx].tolist(),\n  File \"/kaggle/working/greedy_inference.py\", line 7, in loop_version_from_tag_table_to_triplets\n    raw_table_id = torch.tensor(tag_table)\nKeyboardInterrupt\n","output_type":"stream"}]},{"cell_type":"code","source":"# sent\n# 25 precision: 0.519058\trecall: 0.569149\tf1: 0.542950\n# 26 worse \n# 27 with lower_case precision: 0.453846\trecall: 0.627660\tf1: 0.526786\n# 28 same as previos but 4 epochs 0.563338\trecall: 0.574468\tf1: 0.568849\n# 43 diff weights(A 3 O 3) + hd 64 precision: 0.500330\trecall: 0.575988\tf1: 0.535500\n# 44 diff weights(A 3 O 3) + hd 128 precision\n# 78 gcn, weights, hd 64 ... 0.52  \n# 79 gcn eye, weights, hd 64 ... 0.52  \n# 97 gcn updated adj -- so-so 1 epoch is enought\n# 98 Gelu + 3 gcn_layers gcn dropout 0.5\n\n# full\n# 30 precision: 0.616236\trecall: 0.500750\tf1: 0.552523\n# 40 precision: 0.729138\trecall: 0.399550\tf1: 0.516223\n# 41 diff weights(A 2 O 2) precision: 0.568182\trecall: 0.505997\tf1: 0.535289\n# 42 diff weights(A 3 O 3) precision: 0.566641\trecall: 0.557721\tf1: 0.562146\n# 84 0.592593\trecall: 0.527736\tf1: 0.558287\n# 103 fixed gcn 1D precision: 0.545067\trecall: 0.575712\tf1: 0.559971\n","metadata":{"execution":{"iopub.status.busy":"2024-04-13T16:25:54.733331Z","iopub.execute_input":"2024-04-13T16:25:54.733653Z","iopub.status.idle":"2024-04-13T16:25:54.737887Z","shell.execute_reply.started":"2024-04-13T16:25:54.733622Z","shell.execute_reply":"2024-04-13T16:25:54.737024Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}